---
title: "Garden Experiment Power Analysis"
output:
  #pdf_document: default
  html_document: default
    #df_print: paged
---

# Introduction

In our experiment we assumed simple one-way classification with one random effect (random intercept model) of a following form:
$$\begin{matrix} \mathbb{E} [y_{ij}|a_j] = \mu + \beta_ix_{ij} + a_j + \varepsilon_{ij} \\ y_{ij}|a_j \sim indep.\ G\\ a_j \sim i.i.d.\ \mathcal{N}(0,\sigma_a^2) \end{matrix}$$
where, $y_{ij}$ represents community descriptor under the treatement $i \in (1,..., 6)$, within the block $j \in (1,..., 6)$, and $G$ is a distribution for the $y_{ij}|a_j$ with variance $\sigma^2_{\varepsilon}$.

In order to calculate power of our experimental setup (randomized complete block design with six treatments and six control plots) we used estimates for species richness and abundance of plants in young successional tropical forests available in the literature. These included mean values (intercept), and local (within block) and regional (between block) variations of these descriptors.

For the purposes of our exploratory analyses we focused on considerably strong effects of approximately 20% change of the mean relative to the baseline values of our descriptors. With a given effect size we were able to estimate the numbe rof blocks optimal to obtain acceptable 80% power. Next, we explored how different levels of variation between blocks and residual variation affect power of our tests. We also explore how sensitive was power to variability of estimated parameters.

We performed Monte Carlo simulations, using the *rsims* package (Green and MacLeod, 2016) in R to simulate hypothetical data-sets based on expected *random effect variation* (between block variation) $\sigma_{a}$, *within block variation* or *residual variance* $\sigma^2_{\varepsilon}$, for a given effect size.

# Biomass

## Estimates of variation

It is difficult to find estimates of variation in biomass for early successional tropical forests. In one paper Sierra et al. (2007) estimated a function of secondary forest biomass. Using their estimates of the biomass as a function of the forest age:

```{r setup, include=TRUE, echo=F, fig.height=3, fig.width=3}
age=seq(0,50, by=0.5)
TAGB = 247*(1 - exp(-0.068*age))^2.886
plot(TAGB~age, type = "l")
```

Unfortunately there are no estimates of variaiton for the functional responce, however totoal aboveground biomass for secondary forests was showed to be 46.4 $\pm$ 4.3 T/ha (standard deviation) which gives for our small plots an estimate of biomass around `r 46.4*0.0025*1000`kg/ha indicating rather low variabilitiy at least at the later stages of succession (what is the age of this forest and what type of forest is this why is it relervant, are there any closer estimates?). From the functional responce above we expected to have approximately `r 247*(1 - exp(-0.068))^2.886 * 1000` kilograms of above ground biomass. With probably higher variation. I estimated based on simple proportional relationship that sd for early successional gardens might be around (7 kg). To have standard deviation for a biomass equal to 7 we numerically estimated the necessary variance for the normal distribution. That turned out to be $\sigma^2_{block} \sim$ 0.0054.


```{r, include = T, echo=F}
# Is this right?
mu=log(95)
sigma2 = 0.0054
sd = sqrt(sigma2)
# Histogram of biomasses
vals2 <- rlnorm(100000, mu, sd) # inputs are the mu and sd of the noorm vals
hist(vals2, breaks=100, probability=T)
```
Fig. Histogram of final biomasses coming from a log-normal distribution with expected standard deviation being $\pm$ 7kg and expected mean being around 95kg. 

With these estimates we can now create a hypothetical dataset. Create a dataset with six treatments within six experimental blocks.

## Randomization

```{r, echo=FALSE, warning=F, message=F}

# Loading packages and defining functions

library(ggplot2)
library(lmerTest)
library(simr)
library(lattice)
library(latticeExtra)

genDatNorm <- function(ngard = 6,    # number of blocks/gardens
                    nplot = 6,    
                    mu = log(95),   # global average log[bio]
                    fung = 0,  # effect size for fungicide
                    ins = 0,  # effect size for insecticide
                    h1 = 0,     # effect size herbivory low
                    h2 = -5,     # effect size herbivory high
                    pred = 0,  # effect size predator
                    sdg = 0.07332, # standrad dev for the random effect
                    sd = 1){    # standard dev for the residuals 
  gard = rep(LETTERS[1:ngard], each = nplot)         # garden label
  gardeff = rep(rnorm(ngard, 0, sdg), each = nplot) # garden effect
  ploteff = rnorm(ngard*nplot, 0, sd)                # noise for plots
  # print(paste("Generating data with sd garden:",sdg," and error var", sd))
  # Simulate the explanatory variables
  treat <- c()
  for (g in 1:ngard){treat <- c(treat,
                                sample(c("c","f","i","h1","h2","p"), nplot))}
  insecticide <- as.numeric(treat == "i")
  fungicide   <- as.numeric(treat == "f")
  herbivory1  <- as.numeric(treat == "h1")
  herbivory2  <- as.numeric(treat == "h2")
  predator    <- as.numeric(treat == "p")
  bio <- mu + fung*fungicide + ins*insecticide + h1*herbivory1 + h2*herbivory2 + pred*predator + gardeff + ploteff
  ds <- as.data.frame(cbind(bio,
                            gard,
                            treat))
  
  ds$bio <- as.numeric(as.character(ds$bio))
  return(ds)
}

randDat <- function(rands=9, pattern=c(1, 0, 0,-0.05,0,0), mu=log(95), sdg=0.07332, sd=1, ngard = 6, nplot = 6){
  # This function uses genDatNorm function to create random dataset and performs linear mixed model analysis. It reports the proportion of datasets where a specified pattern of significance has occured: pattern <- c(int,fung,h1,h2,ins,pred)
  fits <- c()
  dss <- data.frame()
  for (rand in 1:rands){
    ds <- genDatNorm(ngard = ngard,
                     nplot = nplot,
                     mu=mu,
                     fung = pattern[2],
                     h1 = pattern[3],
                     h2 = pattern[4],
                     ins=pattern[5],
                     pred = pattern[6],
                     sdg = sdg,
                     sd = sd)
    dss <- rbind(dss, as.data.frame(ds))
    fitted_model <- lmer(bio~treat+(1|gard), data = ds)
    sfm <- summary(fitted_model)
    # print(sfm)
    # print(pattern)
    res <- sum((sfm$coefficients[, "Pr(>|t|)"] < 0.05) == (pattern != 0)) == 6
    fits <- c(fits, res)
  }
  return(list(fits = c(fits), data=dss))
}

```

Here we use our estimates to analyze power of our design to detect decrease in plant biomass of about 5kg. This will depend on the estimated between- and within-block variation. 

```{r, echo=F}
# pattern <- c(int,fung,h1,h2,ins,pred)
mu = 95
mcrands <- 99
sdg = sqrt(sigma2)
sd = sqrt(sigma2)
eff_size = -12
leff_size = log((mu + eff_size)/mu)

library(simr)
library(ggplot2)

eff_size = -10
mu = 95
leff_size = log((mu + eff_size)/mu)
treat <- c("c","f","h1","h2","i","p")
gard <- LETTERS[1:20]

dat <- expand.grid(gard=gard, treat = treat)

bioexp <- makeLmer(y~treat+(1|gard),
                     fixef = c(log(95),0,0,leff_size,-leff_size,-leff_size/2), 
                     VarCorr = 0.01,
                     sigma = sqrt(0.01),
                     data=dat)


dt <- getData(bioexp)

plt <- ggplot(dt, aes(x = treat, y = y, colour = gard))
plt + geom_jitter(width = 0.2, size=2, alpha=0.15) +
  theme_bw() +
  ylab("Biomass [kg]")

pc2 <- powerCurve(bioexp, along = "gard", breaks=c(3,6,9,12), nsim=99)
plot(pc2)
```

Here we show an example dataset generated using log-normal mean `r mu`, between-block standard deviation $\sqrt{\sigma_{block}} =$ `r round(sqrt((exp(sdg^2)-1)*exp(2*log(mu) + sdg^2)),2)`, within-block standard deviation $\sqrt{\sigma_{error}}=$ `r round(sqrt((exp(sd^2)-1)*exp(2*log(mu) + sd^2)),2)` and effect size of `r eff_size` kg.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
res <- randDat(rands=mcrands, 
               pattern=c(1,0,0,leff_size,0,0),
               mu=log(mu),
               sdg,
               sd)
rd <- res$fits

#An example dataset simulated based on our variance estimates.
# An example simulat
# ds <- genDat(ins=-10)
plt <- ggplot(res$data, aes(x = treat, y = exp(bio)))
plt + geom_jitter(width = 0.2, size=2, col="grey50", alpha=0.15) +
  theme_bw() +
  stat_summary(fun.data=mean_sdl, fun.args = list(mult=1), 
                 geom="errorbar", width=0.2, lwd=1.5) +
  stat_summary(fun.y=mean, geom="point", cex = 5) +
  ylab("Biomass [kg]")

p_hat <- sum(rd/mcrands)
# p_hat + c(-1,1)*1.96*sqrt(p_hat*(1-p_hat)/mcrands)

# Bootstraped confidence intervals
bootSE <- sqrt((sum((rd - mean(rd))^2)/(mcrands -1)))
bootVar <- bootSE^2
# p_hat + c(-1,1)*1.96*sqrt(bootVar/mcrands)
```
Fig . Simulated `r mcrands` datasets with 6 treatments grouped within six blocks and a hypothetical effect size of high herbivory (h2) to be `r eff_size`.

With the above assumptions we were able to obtain the power of `r round(p_hat,2)` $\pm$ `r round(1.96*sqrt(bootVar/mcrands),2)` (95% bootstraped CI). Which is within acceptable level of statistical power.

# Species richness and woody plant abundance

## Estimates of variation

We expected to find approximately 30 $\pm$ 5 plant species (herbaceous and woody plants) per plot (Leps, personal communication). It is difficult to estimates for the abundance of stems having DBH greater of equal to 1cm. However, Based on Whitfeld et al. (2012) and our own experience we expected to have (similarily to the number of species) approximately 30 $\pm$ 5 stems per 25m$^2$ experimental plot.

## Randomization

As above we create random dataset for for number of species and abundance of stems $\leq$ 1 cm DBH, and estimate the expected power of our design.

```{r,echo=FALSE, warning=FALSE, message=FALSE}
# Poisson random numbers
spsdg <- 5 # standared deviation for stems between blocks
spsd <- 5  #standard deviation of the residual errors

# What are these, what does 
params <-  c(log(30),    0,  0, -0.1,  0,    0)

treat <- c("c","f","h1","h2","i","p")
gard <- c("g1","g2","g3","g4","g5","g6")
dat <- expand.grid(treat = treat,gard=gard)

datdf <- data.frame()
for (rand in 1:mcrands){
  
  lambda <- exp(params[1]+params[2]*(dat$treat == "f")+
                params[3]*(dat$treat == "h1") + 
                params[4]*(dat$treat == "h2") + 
                params[5]*(dat$treat ==  "i") + 
                params[6]*(dat$treat ==  "p")) +
  rep(rnorm(6, 0, 5), each = 6)#random effect of block
  dat$abu <- rpois(36, lambda)
  datdf <- rbind(datdf, dat)
}


lambda <- exp(params[1]+params[2]*(dat$treat == "f")+
                params[3]*(dat$treat == "h1") + 
                params[4]*(dat$treat == "h2") + 
                params[5]*(dat$treat ==  "i") + 
                params[6]*(dat$treat ==  "p")) +
  rep(rnorm(6, 0, 5), each = 6)#random effect of block
dat$abu <- rpois(36, lambda)

abuplot <- ggplot(datdf, aes(x = treat, y = abu))
abuplot + geom_jitter(width = 0.2, alpha=0.1, col="grey50") + 
  xlab("Treatment") + ylab("No of stems per 25 m^2 plot")

#fitted_model <- glmer(abu~treat+(1|gard), data=dat, family = "poisson")
#summary(fitted_model)

```

Fig X. ...

# Sample  size, within-block and between-block variation

Here we want do analyze sensitivity of our estimates on the expected power of our analyses. We perform a randomization manipulating three parameters: number of samples, between block variation and within block noise (within block variation) 

```{r}
# mcrands <- 999
# wbsd <- round(sqrt(seq(0.0005, 0.01, by = 0.0025)),3)
# bbsd <- round(sqrt(seq(0.0005, 0.01, by = 0.0025)),3)
# ssize <- seq(5, 20, by=1)#sample size
# # leff_size varry the effect size? 
# # Random effect standard deviation
# resmatgard1 <- matrix(0, 
#                       nrow = length(wbsd),
#                       ncol = length(ssize))
# rownames(resmatgard1) <- as.character(round(wbsd, 3))
# colnames(resmatgard1) <- ssize
# 
# for(row in wbsd){
#   for(col in ssize){
#     temp_res <- randDat(rands=mcrands,
#                     pattern=c(1,0,0,leff_size,0,0),
#                     mu=log(mu),
#                     sdg = row,
#                     sd = sd,
#                     ngard = col,
#                     nplot = 6)
#     rd <- temp_res$fits
#     p_hat <- sum(rd/mcrands)
#     
#     resmatgard1[as.character(row),as.character(col)] <- p_hat
#     
#   }
# }
# 
# levelplot(resmatgard1, xlab = "Between block variation",
#           ylab = "Number of blocks") +
#   as.layer(contourplot(resmatgard1, col = "red"))
# 
# 
# # With simr
# vars <- seq(0.003, 0.090, by=0.015)
# resmatgard1 <- matrix(0, 
#                       nrow = length(vars),
#                       ncol = length(vars))
# rownames(resmatgard1) <- as.character(round(vars, 3))
# colnames(resmatgard1) <- as.character(round(vars, 3))
# 
# mcrands <- 99
# counter <- 1
# dims    <- length(vars)
# for (i in vars){
#   for(j in vars){
#     counter <- counter + 1
#     print(counter/(dims*dims))
#     VarCorr(bio_rbl) <- i  #
#     sigma(bio_rbl) <- sqrt(j)
#     est <- powerSim(bio_rbl, nsim = mcrands)
#     resmatgard1[as.character(i),
#                 as.character(j)] <- summary(est)$mean
#   }
# }
# 
# levelplot(resmatgard1, ylab = "Sigma",
#           xlab = "VarCorr")

```

# Literature

Green P, MacLeod CJ (2016). “simr: an R package for power analysis
of generalised linear mixed models by simulation.” _Methods in
Ecology and Evolution_, *7*(4), 493-498. doi:
10.1111/2041-210X.12504